# Grega Močnik
------------
## About 
Grega Močnik, is scientifically active in the fields of video signal processing and in the Internet of Things, focusing his research on the implementation of communication protocols on embedded systems. He is a doctoral student and as part of his studies he develops video signal processing algorithms that are similar to human image perception. He is involved in several professional and scientific projects. He is also a mentor to students in diverse projects and master’s theses.

## Bibliography
<details>
<summary> Pupillometric parameters of alertness during unpredictable but not predictable smooth pursuit neck torsion test are altered in patients with neck pain disorders: a cross-sectional study </summary>

#### *Pupillometric parameters of alertness during unpredictable but not predictable smooth pursuit neck torsion test are altered in patients with neck pain disorders: a cross-sectional study*
#### Abstract 
> Despite commonly investigated predictable smooth-pursuit neck-torsion tasks (SPNT) in neck pain patients, unpredictable conditions have been seldom investigated but are indicative of preserved oculomotor functions during neck torsion. Although not previously studied, some speculations about compensatory cognitive mechanisms such as increased phasic alertness during unpredictable tasks were suggested. The aim of this study was to investigate eye movement accuracy and pupillometric responses during predictable and unpredictable SPNT test in neck pain patients and asymptomatic controls. Eye movements (gain and SPNT-difference) and pupillometry indicative of tonic (average and relative pupil diameter) and phasic (index of cognitive activity-ICA) alertness were measured in 28 idiopathic neck pain patients and 30 asymptomatic individuals using infrared video-oculography during predictable and unpredictable SPNT test. Gain in unpredictable SPNT test was lower as compared to predictable tasks and presented with similar levels in neutral and neck torsion positions, but not in the predictable SPNT test. ICA was lower during neutral position in all tasks in patients as compared to control group but increased during neck torsion positions in unpredictable tasks. Relative pupil diameters presented with no differences between the groups or neck positions, but the opposite was observed for average pupil diameter. Higher ICA indicates an increase in phasic alertness in neck pain patients despite no alterations in oculomotor control during SPNT test. This is the first study to indicate cognitive deficits in oculomotor task in neck pain patients. The latter could negatively affect other tasks where additional cognitive resources must be involved.
#### Cite: 
> Majcen Rosker, Z., Mocnik, G., Kristjansson, E. et al. Pupillometric parameters of alertness during unpredictable but not predictable smooth pursuit neck torsion test are altered in patients with neck pain disorders: a cross-sectional study. Exp Brain Res 241, 2069–2079 (2023). https://doi.org/10.1007/s00221-023-06648-z
</details>
<details>
<summary> Capturing Conversational Gestures for Embodied Conversational Agents Using an Optimized Kaneda–Lucas–Tomasi Tracker and Denavit–Hartenberg-Based Kinematic Model</summary>

#### *Capturing Conversational Gestures for Embodied Conversational Agents Using an Optimized Kaneda–Lucas–Tomasi Tracker and Denavit–Hartenberg-Based Kinematic Model*

#### Abstract 
> In order to recreate viable and human-like conversational responses, the artificial entity, i.e., an embodied conversational agent, must express correlated speech (verbal) and gestures (non-verbal) responses in spoken social interaction. Most of the existing frameworks focus on intent planning and behavior planning. The realization, however, is left to a limited set of static 3D representations of conversational expressions. In addition to functional and semantic synchrony between verbal and non-verbal signals, the final believability of the displayed expression is sculpted by the physical realization of non-verbal expressions. A major challenge of most conversational systems capable of reproducing gestures is the diversity in expressiveness. In this paper, we propose a method for capturing gestures automatically from videos and transforming them into 3D representations stored as part of the conversational agent’s repository of motor skills. The main advantage of the proposed method is ensuring the naturalness of the embodied conversational agent’s gestures, which results in a higher quality of human-computer interaction. The method is based on a Kanade–Lucas–Tomasi tracker, a Savitzky–Golay filter, a Denavit–Hartenberg-based kinematic model and the EVA framework. Furthermore, we designed an objective method based on cosine similarity instead of a subjective evaluation of synthesized movement. The proposed method resulted in a 96% similarity.

#### Cite: 
> G. Močnik, Z. Kačič, R. Šafarič, and I. Mlakar, “Capturing Conversational Gestures for Embodied Conversational Agents Using an Optimized Kaneda–Lucas–Tomasi Tracker and Denavit–Hartenberg-Based Kinematic Model,” Sensors, vol. 22, no. 21, p. 8318, Oct. 2022, [doi: 10.3390/s22218318](https://www.mdpi.com/1424-8220/22/21/8318)
</details>

---




## Software
<details>
  <summary> 
    #### FlySight Eye
#### English: 
    FlySight Eye is software designed for capturing data from eye trackers, intended for use in medical environments to monitor patients. The software allows for easy management of patient data by capturing and organizing information needed for analyses and studies.

Key Features:

Data Capture from Eye Trackers:
FlySight Eye enables connection to advanced eye trackers and captures precise data on eye movements and other related metrics.
Supported trackers: Pupil and Tobii, which provide real-time accurate eye tracking.
Patient Management:
The software offers an interface for easily adding and editing patient data. The data includes:
Patient ID
Gender
Age
Additional details such as contact information, medical history, etc.
The data management is tailored for quick and accurate patient overviews, improving workflow in medical settings.
Eye Tracker Connection and Calibration:
Users can easily connect to Pupil and Tobii eye trackers.
The software includes control features for calibration and diagnostics of the trackers, ensuring accuracy in data capture.
Data Capture:
The software captures various types of data, including:
HD resolution video views that provide a visual overview of the patient's field of view during tracking.
Raw accelerometer and gyroscope data on head movements, which help understand movement dynamics during eye tracking.
Pupillometric data capturing pupil width and responsiveness, a key parameter in neurological and ophthalmological analyses.
FlySight Eye offers a robust and intuitive solution for capturing data from eye trackers, compatible with the most advanced tracking systems.

#### Slovenian:
FlySight Eye je programska oprema za zajem podatkov iz sledilnikov za oči, namenjena uporabi v medicinskih okoljih za spremljanje pacientov. Programska oprema omogoča preprosto upravljanje podatkov pacientov, z zajemom in organizacijo informacij, potrebnih za izvajanje analiz in študij.
Ključne funkcionalnosti:
1.	Zajem podatkov iz sledilnikov za oči:
-	FlySight Eye omogoča povezavo z naprednimi sledilniki za oči in zajema natančne podatke o gibanju oči ter drugih povezanih meritev.
-	Podprti sledilniki: Pupil in Tobii, ki zagotavljata natančno sledenje očem v realnem času.
2.	Upravljanje pacientov:
o	Programska oprema ponuja vmesnik za enostavno dodajanje in urejanje podatkov pacientov. Podatki vključujejo:
	Pacientov ID
	Spol
	Starost
	Dodatne podatke, kot so kontaktne informacije, zgodovina bolezni ipd.
o	Upravljanje podatkov je prilagojeno za hitre in natančne vpoglede v paciente, kar izboljša potek dela v medicinskih okoljih.
3.	Povezava in kalibracija sledilnikov za oči:
o	Uporabnikom omogoča enostavno povezavo s sledilniki za oči Pupil in Tobii.
o	Programska oprema vključuje kontrolne funkcije za kalibracijo in diagnostiko sledilnikov, kar zagotavlja natančnost pri zajemu podatkov.
4.	Zajem podatkov:
o	Programska oprema zajema več vrst podatkov, vključno z:
	Video pogledi v HD resoluciji, ki omogočajo pregled vidnega polja pacienta med sledenjem.
	Pospešek in žiroskopski surovi podatki o gibanju glave, kar pomaga razumeti dinamiko gibanja med sledenjem očem.
	Pupilometrični podatki, ki zajemajo širino in odzivnost zenic, kar je ključni parameter pri nevroloških in oftalmoloških analizah.
FlySight Eye omogoča robustno in intuitivno rešitev za zajemanje podatkov s sledilnikov za oči, združljivo z najnaprednejšimi sistemi sledenja.

  </summary>
</details>

<details>
  <summary> 
    #### FlySight IMU
  </summary>
</details>

<details>
  <summary> 
    #### FlySight Analysis
  </summary>
</details>

<details>
  <summary> 
    #### IMUCVP Capture
  </summary>
</details>

<details>
  <summary> 
    #### IMUCVP Analysis
  </summary>
</details>


